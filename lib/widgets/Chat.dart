import 'dart:convert';
import 'dart:typed_data';

import 'package:audioplayers/audioplayers.dart';
import 'package:avatar_glow/avatar_glow.dart';
import 'package:flutter/material.dart';
import 'package:gather_mvp/widgets/sound_recorder.dart';
import 'package:gather_mvp/theme.dart';
import 'package:googleapis/texttospeech/v1.dart';
import 'package:googleapis_auth/auth_io.dart';
import 'package:path_provider/path_provider.dart';
import 'package:provider/provider.dart';
import 'package:http/http.dart' as http;

import '../Google_API_Credentials.dart';
import '../Provider/provider_chat.dart';
import '../models/chat_in_chat.dart';
import 'finish_dialog.dart';
import 'messages_in_chat.dart';

class NewChatScreen extends StatefulWidget {
  const NewChatScreen({super.key});

  @override
  State<NewChatScreen> createState() => _NewChatScreenState();
}

class _NewChatScreenState extends State<NewChatScreen> {
  final recorder = SoundRecorder();

  int voiceIndex = 0;

  bool canSpeak = false;

  String chatId = '';

  List<ChatInChat> chatList = [];

  late AutoRefreshingAuthClient client;

  final ScrollController scrollController = ScrollController();

  @override
  void initState() {
    super.initState();
    chatId = context.read<ProviderChat>().chatId;
    chatList.add(ChatInChat(DateTime.now(),
        context.read<ProviderChat>().initialChat, 'GPT', false, [''], true));

    getRecommend(0);

    initAPI().then(
        (value) => speak(context.read<ProviderChat>().initialChat).then((_) => {
              recorder.init().then((value) => {
                    setState(() {
                      canSpeak = true;
                    })
                  })
            }));
  }

  Future<void> initAPI() async {
    client = await clientViaServiceAccount(
        credentials, ['https://www.googleapis.com/auth/cloud-platform']);
  }

  @override
  void dispose() {
    recorder.dispose();
    super.dispose();
  }

  // ë…¹ìŒ ì¢…ë£Œ ë²„íŠ¼ ëˆ„ë¦„
  void transcribe(String prompt) async {
    await recorder.stop();
    setState(() {
      canSpeak = false;
    });

    // WaitingChatBubble ì¶”ê°€
    chatList.add(ChatInChat(DateTime.now(), "", 'me', true, [''], false));
    setState(() {});

    // ë‚´ê°€ ë§í•œ ê±¸ whisperë¡œ text ë³€í™˜
    String transcribe = await recorder.transcribe(prompt);

    if (transcribe != 'error' && transcribe != 'recorder not playing') {
      setState(() {});

      chatList.removeLast();
      chatList
          .add(ChatInChat(DateTime.now(), transcribe, 'me', false, [''], true));
      setState(() {});

      // 1. BEì—ì„œ textë¥¼ documentì— ì‚½ì…í•  ìˆ˜ ìˆë„ë¡ ë³´ë‚´ì¤€ë‹¤
      await sendToBE(transcribe);

      // 2. BEì— whisper transcribe ëœ ê²ƒì— ëŒ€í•œ tip ìš”ì²­
      if (chatList.length % 2 == 0) {
        getShortTip(chatList.length - 1);
        getTip(chatList.length - 1);
      }

      // WaitingChatBubble ì¶”ê°€
      chatList.add(ChatInChat(DateTime.now(), "", 'waiting', true, [''], true));
      setState(() {});

      // 3. BEì— textë¥¼ ë³´ë‚´ì„œ ê°ê° tipê³¼ GPTì˜ ëŒ€ë‹µì„ ì–»ì–´ë‚¸ë‹¤.
      askGPT(transcribe);
    }
  }

  Future getShortTip(int index) async {
    String uri = 'http://101.101.209.54:80/chat/shortTip';
    // String uri = 'http://43.201.21.32:80/chat/shortTip';

    http.Response response = await http.post(Uri.parse(uri),
        headers: <String, String>{'Content-Type': "application/json"},
        body: jsonEncode(<String, dynamic>{
          'idx': index,
          'chat_id': chatId,
        }));

    String responseBody = utf8.decode(response.bodyBytes);
    Map<String, dynamic> responseMap = json.decode(responseBody);
    int idx = responseMap['idx'];
    bool ok = responseMap['tip_ok'];
    double credit = responseMap['credit'];

    if (!mounted) return;

    if (ok) {
      String tipSentence = responseMap['tip_sentence'];
      String tipExplain = '';
      ChatInChat chatInChat = chatList[idx];
      chatInChat.helpText = [tipSentence, tipExplain];

      chatList[idx] = chatInChat;

      setState(() {});

      String uri2 = 'http://101.101.209.54:80/chat/translate';
      // String uri2 = 'http://43.201.21.32:80/chat/translate';

      // ë²ˆì—­ ìš”ì²­ API
      http.Response response = await http.post(Uri.parse(uri2),
          headers: <String, String>{'Content-Type': "application/json"},
          body: jsonEncode(<String, dynamic>{
            'idx': index,
            'chat_id': chatId,
          }));

      String responseBody2 = utf8.decode(response.bodyBytes);
      Map<String, dynamic> responseMap2 = json.decode(responseBody2);
      int idx2 = responseMap2['idx'];
      String result = responseMap2['result'];
      // double credit2 = responseMap['credit'];

      ChatInChat chatInChat2 = chatList[idx2];
      List<String> helpText = chatInChat2.helpText;
      helpText[1] = result;
      chatInChat2.helpText = helpText;
      chatList[idx2] = chatInChat2;

      setState(() {});
    } else {
      ChatInChat chatInChat = chatList[idx];
      chatInChat.helpText = ['AI ì„ ìƒë‹˜ì´ ê³ ë¯¼í•˜ë‹¤ ì“°ë ¤ì¡Œì–´ìš” ğŸ™ƒ'];
    }
  }

  Future getTip(int index) async {
    String uri = 'http://101.101.209.54:80/chat/tip';
    // String uri = 'http://43.201.21.32:80/chat/tip';

    await http.post(Uri.parse(uri),
        headers: <String, String>{'Content-Type': "application/json"},
        body: jsonEncode(<String, dynamic>{
          'idx': index,
          'chat_id': chatId,
        }));
  }

// TTS
  Future speak(String text) async {
    try {
      AudioPlayer audioPlayer = AudioPlayer();

      // Google TTS API
      final input = SynthesisInput(text: text);
      final voice = VoiceSelectionParams(
          languageCode: 'en-US',
          name: context.read<ProviderChat>().randomVoice);
      final audioConfig = AudioConfig(audioEncoding: "MP3");

      final synthesizeSpeechRequest = SynthesizeSpeechRequest(
          audioConfig: audioConfig, input: input, voice: voice);

      SynthesizeSpeechResponse synthesizeSpeechResponse =
          await TexttospeechApi(client)
              .text
              .synthesize(synthesizeSpeechRequest);

      List<int> audioContent =
          synthesizeSpeechResponse.audioContentAsBytes; // List<int> ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë°›ìŒ
      //

      Source source = BytesSource(Uint8List.fromList(audioContent));
      audioPlayer.play(source);
    } catch (error) {
      print(error);
    }
  }

  Future sendToBE(String input) async {
    String uri = 'http://101.101.209.54:80/chat/insertDB';
    // String uri = 'http://43.201.21.32:80/chat/insertDB';

    http.Response response = await http.post(Uri.parse(uri),
        headers: <String, String>{'Content-Type': "application/json"},
        body: jsonEncode(<String, dynamic>{
          'text': input,
          'chat_id': chatId,
        }));
    String responseBody = utf8.decode(response.bodyBytes);
    Map<String, dynamic> responseMap = json.decode(responseBody);

    return responseMap['result'];
  }

  Future getRecommend(int index) async {
    String uri = 'http://101.101.209.54:80/chat/recommend';
    // String uri = 'http://43.201.21.32:80/chat/recommend';

    http.Response response = await http.post(Uri.parse(uri),
        headers: <String, String>{'Content-Type': "application/json"},
        body: jsonEncode(<String, dynamic>{
          'idx': index,
          'chat_id': chatId,
        }));
    String responseBody = utf8.decode(response.bodyBytes);
    Map<String, dynamic> responseMap = json.decode(responseBody);

    int idx = responseMap['idx'];
    String recommendedAnswer = responseMap['recommended answer'];

    ChatInChat chatInChat = chatList[idx];
    chatInChat.helpText = [recommendedAnswer];

    chatList[idx] = chatInChat;

    setState(() {});
  }

  Future askGPT(String input) async {
    String uri = 'http://101.101.209.54:80/chat/askGPT';
    // String uri = 'http://43.201.21.32:80/chat/askGPT';

    http.Response response = await http.post(Uri.parse(uri),
        headers: <String, String>{'Content-Type': "application/json"},
        body: jsonEncode(<String, dynamic>{
          'text': input,
          'chat_id': chatId,
        }));
    String responseBody = utf8.decode(response.bodyBytes);
    Map<String, dynamic> responseMap = json.decode(responseBody);

    bool finish = responseMap['finish'];
    String result = responseMap['result'];

    // ë¹™ê¸€ë¹™ê¸€ ë„ëŠ” ì  ì‚­ì œ
    chatList.removeLast();

    // recommend ì œì™¸ ê°’ ì‚½ì…
    chatList
        .add(ChatInChat(DateTime.now(), result, 'GPT', false, [''], !finish));
    setState(() {});

    if (!finish) {
      getRecommend(chatList.length - 1);
    }

    await speak(result);

    setState(() {
      canSpeak = true;
    });

    if (finish) {
      // ignore: use_build_context_synchronously
      showDialog(
          context: context,
          builder: (context) {
            return const FinishDialog();
          });
    } else {}
  }

  @override
  Widget build(BuildContext context) {
    double screenWidth = MediaQuery.of(context).size.width;
    return SizedBox(
      width: screenWidth / 2,
      child: Scaffold(
        backgroundColor: Colors.transparent,
        floatingActionButtonLocation: FloatingActionButtonLocation.centerFloat,
        floatingActionButton: AvatarGlow(
          animate: recorder.isRecording ?? false,
          glowColor: Colors.red,
          endRadius: 75.0,
          duration: const Duration(milliseconds: 1000),
          repeatPauseDuration: const Duration(milliseconds: 100),
          repeat: true,
          child: ElevatedButton(
            style: ElevatedButton.styleFrom(
              surfaceTintColor: Colors.white,
              backgroundColor:
                  recorder.isRecording ?? false ? Colors.red : Colors.amber,
              shape: const CircleBorder(),
            ),
            onPressed: () async {
              if (recorder.isRecording ?? false) {
                transcribe(chatList[chatList.length - 1].chat);
              } else if (recorder.isRecording == false && canSpeak == true) {
                await recorder.record();
                setState(() {});
              }
            },
            child: SizedBox(
              height: 75,
              width: 75,
              child: Icon(
                recorder.isRecording ?? false ? Icons.stop : Icons.mic,
                size: 50,
                color: Colors.white,
              ),
            ),
          ),
        ),
        body: Scrollbar(
          controller: scrollController,
          thumbVisibility: true,
          child: Container(
            padding: const EdgeInsets.fromLTRB(30.0, 30.0, 30.0, 150.0),
            child: Column(children: [
              Expanded(
                child: MessagesInChat(
                  chatList: chatList,
                  scrollController: scrollController,
                ),
              ),
            ]),
          ),
        ),
      ),
    );
  }
}
